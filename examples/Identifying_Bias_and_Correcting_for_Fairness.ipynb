{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Identifying Bias and Correcting for Fairness.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirstenSchulz/AIF360/blob/master/examples/Identifying_Bias_and_Correcting_for_Fairness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie3qi_ieULZ1",
        "colab_type": "text"
      },
      "source": [
        "#Project 1 - Identifying Bias and Correcting for Fairness\n",
        " by Kirsten Schulz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSuVBf4kUl-i",
        "colab_type": "text"
      },
      "source": [
        "##Part 1 - Overview of AIF360\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX_D-FEZCAs4",
        "colab_type": "text"
      },
      "source": [
        "This work is based on a paper by IBM, AI Fairness 360: An Extensible Toolkik for Detecting, Understanding, and Mitigating Unwanted Algororitmic Bias.\n",
        "<p>\n",
        "Fairness is a complex and multi-faced concept; therefore there is not one definition, neither one measure, and different definitions produce different outcomes. The burden is on Machine Learning (ML) and Artificial Intelligence (AI) developers. They have to decide if they should debiase the data, the model or the predictions.\n",
        "<p>\n",
        "Some of the terminology that we are using in this notebook are listed below.\n",
        "<p>\n",
        "<b>Favorable label</b> is a label whose value corresponds to an outcome that provides an advantage to the recipient.\n",
        "<p>\n",
        "<b>Protected attribute</b> is an attribute that partitions a population into groups that have parity in terms of the benefit received.\n",
        "<p>\n",
        "<b>Priviledge value</b> of a protected attribute is a group that has historically been at systematic advantage.\n",
        "<p>\n",
        "<b>Group fairness</b> is the goal of the groups defined by protected attributes receiving similar treatment or outcomes. \n",
        "<p>\n",
        "<b>Individual fairness</b> is the goal of similar individuals receiving similar treatment or outcomes.\n",
        "<p>\n",
        "<b>Bias</b> is a sytematic error. \n",
        "<p>\n",
        "<b>Fairness metrics</b> is a quantification of unwanted bias in training data or models.\n",
        "<p>\n",
        "<b>Bias mitigation algorithms </b> are procedures for reducing unwanted bias in training data or models.\n",
        "<p> There are three places to work towards achieving fairnes with AIF360: during pre-processing, in-processing, and post-processinng. In other words we can apply AIF360 mitigation algorithms to the training data, to the learning model, and to the predictions. Where to do so will depend in what is available to the developer and/or user. All the processes  can be viewed with same relevance by AIF360 but their relevance will also depend on the domain knowledge of the user.\n",
        "<p>\n",
        "The dataset used in this notebook will be structured and it is the German Credit data set.\n",
        "<p>\n",
        "The Metric class and subclasses implement 71 bias metrics. They are often related to the confusion matrix.\n",
        "<p>\n",
        "This assignment has given us awareness of the existence of bias in ML and insights into its mitigation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4MaAPjQVxq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip uninstall aif360[all] -y\n",
        "#!ls /usr/local/lib/python3.6/dist-packages/aif*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNhdVCRlWBeb",
        "colab_type": "code",
        "outputId": "58cf3f71-f470-42ec-90cb-dece28f7e007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'aif360[all]'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aif360[all] in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.0.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (3.2.1)\n",
            "Requirement already satisfied: numba>=0.42.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.48.0)\n",
            "Requirement already satisfied: sphinx-rtd-theme; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.4.3)\n",
            "Requirement already satisfied: jupyter; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.0.0)\n",
            "Requirement already satisfied: BlackBoxAuditing; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.1.54)\n",
            "Requirement already satisfied: pytest>=3.5; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (3.6.4)\n",
            "Requirement already satisfied: tensorflow<2,>=1.13.1; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.15.3)\n",
            "Requirement already satisfied: sphinx; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.8.5)\n",
            "Requirement already satisfied: lime; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (0.2.0.0)\n",
            "Requirement already satisfied: cvxpy>=1.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.0.31)\n",
            "Requirement already satisfied: adversarial-robustness-toolbox>=1.0.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: tqdm; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from aif360[all]) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[all]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->aif360[all]) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21->aif360[all]) (0.15.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[all]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->aif360[all]) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.42.0; extra == \"all\"->aif360[all]) (47.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.42.0; extra == \"all\"->aif360[all]) (0.31.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (4.7.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (7.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter; extra == \"all\"->aif360[all]) (4.10.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from BlackBoxAuditing; extra == \"all\"->aif360[all]) (2.4)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (1.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.5; extra == \"all\"->aif360[all]) (8.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.2.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.29.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.23.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (1.2.2)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (0.15.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.0.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (20.4)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.8.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (0.7.12)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx; extra == \"all\"->aif360[all]) (2.11.2)\n",
            "Requirement already satisfied: pillow==5.4.1 in /usr/local/lib/python3.6/dist-packages (from lime; extra == \"all\"->aif360[all]) (5.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime; extra == \"all\"->aif360[all]) (0.16.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.70.9)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (2.1.2)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (2.0.7.post1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.6.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (1.9.0)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (4.6.3)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (5.3.4)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter; extra == \"all\"->aif360[all]) (19.0.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter; extra == \"all\"->aif360[all]) (0.8.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter; extra == \"all\"->aif360[all]) (4.5.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter; extra == \"all\"->aif360[all]) (5.0.6)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (3.1.5)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter; extra == \"all\"->aif360[all]) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter; extra == \"all\"->aif360[all]) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter; extra == \"all\"->aif360[all]) (1.0.18)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->BlackBoxAuditing; extra == \"all\"->aif360[all]) (4.4.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.2.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx; extra == \"all\"->aif360[all]) (2.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx; extra == \"all\"->aif360[all]) (1.1.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime; extra == \"all\"->aif360[all]) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime; extra == \"all\"->aif360[all]) (2.4.1)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.3.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp>=0.4.1->cvxpy>=1.0; extra == \"all\"->aif360[all]) (0.16.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter; extra == \"all\"->aif360[all]) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter; extra == \"all\"->aif360[all]) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter; extra == \"all\"->aif360[all]) (0.5.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter; extra == \"all\"->aif360[all]) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter; extra == \"all\"->aif360[all]) (0.2.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1; extra == \"all\"->aif360[all]) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX41A2QeVDJC",
        "colab_type": "text"
      },
      "source": [
        "##Part 2 - Executing the credit decision pipeline\n",
        "The credit decision pipeline detects bias and removes it using the reweighting algorithm. This algorithm generates weights for the examples per group before training. The following code is practically a copy of the code provided to us from the example notebook \"Detecting and mitigating age bias on credit decisions.\" I only added a few lines to be able to execute it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL0AjVdiX2kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.insert(1, \"../\")  \n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from aif360.datasets import GermanDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import  load_preproc_data_german\n",
        "\n",
        "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZQsy61zX-lp",
        "colab_type": "code",
        "outputId": "47039ac2-6afe-4fef-d69b-6db1e6559e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
        "!sudo cp german.data /usr/local/lib/python3.6/dist-packages/aif360/data/raw/german"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-14 21:21:25--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79793 (78K) [application/x-httpd-php]\n",
            "Saving to: ‘german.data.4’\n",
            "\n",
            "german.data.4       100%[===================>]  77.92K   276KB/s    in 0.3s    \n",
            "\n",
            "2020-06-14 21:21:26 (276 KB/s) - ‘german.data.4’ saved [79793/79793]\n",
            "\n",
            "--2020-06-14 21:21:27--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4679 (4.6K) [application/x-httpd-php]\n",
            "Saving to: ‘german.doc.4’\n",
            "\n",
            "german.doc.4        100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-06-14 21:21:28 (119 MB/s) - ‘german.doc.4’ saved [4679/4679]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcLy6yfJfZsy",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset and set options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixsiW33Fa2k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_orig = GermanDataset(\n",
        "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
        "                                                 # attribute for \"sex\" which we do not\n",
        "                                                 # consider in this evaluation\n",
        "    privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
        "    features_to_drop=['personal_status', 'sex']  # ignore sex-related attributes\n",
        "\n",
        ")\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5caOIdWbGRl",
        "colab_type": "code",
        "outputId": "8328c36e-52dd-42c1-a8c9-4a64c0892c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Original training dataset",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km9cw7Y6bXBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59HrMvhccIUB",
        "colab_type": "code",
        "outputId": "09b8982a-ade3-4f66-f5f1-af56ee573766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
        "                                               unprivileged_groups=unprivileged_groups,\n",
        "                                               privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Transformed training dataset\"))\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Transformed training dataset",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SHIeVYeWMxT",
        "colab_type": "text"
      },
      "source": [
        "####Findings\n",
        "<p>Before applying reweighting, the difference between the mean outcomes is -0.169905 (in favor of the people 25 years or older). After applying the reweighting algorithm the favorable outcome rates are equal (the difference is zero). The bias in the training data for that particular attribute has been mitigated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnxbkyxORtkb",
        "colab_type": "text"
      },
      "source": [
        "##Part 3 - Applying adversarial debiasing\n",
        "I have chosen adversarial debiasing to explore the in-process method but soon I encountered that the German data set is small  and in some occasions there was not much mitigation of bias and the software even  had a division by zero. I have decided to stick to it in spite of the size issue because of the learning experience. I played with the definition of the priviledge class (anyway this class definition varies from culture to culture) to compensate for it, and with the split of the data set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUkY50UyZlLn",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset and set options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSqwtO3LZYme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_orig = GermanDataset(\n",
        "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
        "                                                 # attribute for \"sex\" which we do not\n",
        "                                                 # consider in this evaluation\n",
        "    privileged_classes=[lambda x: x >= 30],      # age >=25 is considered privileged\n",
        "    features_to_drop=['personal_status', 'sex'] # ignore sex-related attributes\n",
        "\n",
        ")\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.60], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ikt8kYW0ljy",
        "colab_type": "code",
        "outputId": "d3e4648d-66d1-435e-8e55-d489aa4b0453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# print out some labels, names, etc.\n",
        "display(Markdown(\"#### Training Dataset shape\"))\n",
        "print(dataset_orig_train.features.shape)\n",
        "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
        "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
        "display(Markdown(\"#### Protected attribute names\"))\n",
        "print(dataset_orig_train.protected_attribute_names)\n",
        "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
        "print(dataset_orig_train.privileged_protected_attributes, \n",
        "      dataset_orig_train.unprivileged_protected_attributes)\n",
        "display(Markdown(\"#### Dataset feature names\"))\n",
        "print(dataset_orig_train.feature_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Training Dataset shape",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(600, 57)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Favorable and unfavorable labels",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.0 2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Protected attribute names",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['age']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Privileged and unprivileged protected attribute values",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[array([1.])] [array([0.])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Dataset feature names",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['month', 'credit_amount', 'investment_as_income_percentage', 'residence_since', 'age', 'number_of_credits', 'people_liable_for', 'status=A11', 'status=A12', 'status=A13', 'status=A14', 'credit_history=A30', 'credit_history=A31', 'credit_history=A32', 'credit_history=A33', 'credit_history=A34', 'purpose=A40', 'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43', 'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48', 'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63', 'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72', 'employment=A73', 'employment=A74', 'employment=A75', 'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103', 'property=A121', 'property=A122', 'property=A123', 'property=A124', 'installment_plans=A141', 'installment_plans=A142', 'installment_plans=A143', 'housing=A151', 'housing=A152', 'housing=A153', 'skill_level=A171', 'skill_level=A172', 'skill_level=A173', 'skill_level=A174', 'telephone=A191', 'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lijcz2nJ0lj5",
        "colab_type": "text"
      },
      "source": [
        "#### Metric for original test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PG3IAGC0lj7",
        "colab_type": "code",
        "outputId": "8d8022ab-c216-4276-8788-25458e96dbd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# Metric for the original dataset\n",
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
        "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Original training dataset",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.078457\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.159340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTqszdLt0lkB",
        "colab_type": "code",
        "outputId": "c0969b50-8d3c-4348-f8bc-581248c9ef31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "min_max_scaler = MaxAbsScaler()\n",
        "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
        "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
        "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Scaled dataset - Verify that the scaling does not affect the group label statistics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.078457\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.159340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4XxuizL0lkI",
        "colab_type": "text"
      },
      "source": [
        "### Learn plain classifier without debiasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwL8R-3A0lkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load post-processing algorithm that equalizes the odds\n",
        "# Learn parameters with debias set to False\n",
        "sess = tf.Session()\n",
        "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='plain_classifier',\n",
        "                          debias=False,\n",
        "                          sess=sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ala0uK3w0lkV",
        "colab_type": "code",
        "outputId": "203ae44b-0a09-4ddc-b5f6-af11dfd12a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plain_model.fit(dataset_orig_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:188: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n",
            "epoch 0; iter: 0; batch classifier loss: 0.671214\n",
            "epoch 1; iter: 0; batch classifier loss: 0.536403\n",
            "epoch 2; iter: 0; batch classifier loss: 0.537950\n",
            "epoch 3; iter: 0; batch classifier loss: 0.516291\n",
            "epoch 4; iter: 0; batch classifier loss: 0.507715\n",
            "epoch 5; iter: 0; batch classifier loss: 0.468882\n",
            "epoch 6; iter: 0; batch classifier loss: 0.522880\n",
            "epoch 7; iter: 0; batch classifier loss: 0.524104\n",
            "epoch 8; iter: 0; batch classifier loss: 0.493662\n",
            "epoch 9; iter: 0; batch classifier loss: 0.475912\n",
            "epoch 10; iter: 0; batch classifier loss: 0.500915\n",
            "epoch 11; iter: 0; batch classifier loss: 0.445097\n",
            "epoch 12; iter: 0; batch classifier loss: 0.440458\n",
            "epoch 13; iter: 0; batch classifier loss: 0.496094\n",
            "epoch 14; iter: 0; batch classifier loss: 0.482972\n",
            "epoch 15; iter: 0; batch classifier loss: 0.486762\n",
            "epoch 16; iter: 0; batch classifier loss: 0.448134\n",
            "epoch 17; iter: 0; batch classifier loss: 0.458354\n",
            "epoch 18; iter: 0; batch classifier loss: 0.377416\n",
            "epoch 19; iter: 0; batch classifier loss: 0.402523\n",
            "epoch 20; iter: 0; batch classifier loss: 0.390058\n",
            "epoch 21; iter: 0; batch classifier loss: 0.397019\n",
            "epoch 22; iter: 0; batch classifier loss: 0.416128\n",
            "epoch 23; iter: 0; batch classifier loss: 0.389897\n",
            "epoch 24; iter: 0; batch classifier loss: 0.463645\n",
            "epoch 25; iter: 0; batch classifier loss: 0.440098\n",
            "epoch 26; iter: 0; batch classifier loss: 0.419348\n",
            "epoch 27; iter: 0; batch classifier loss: 0.410847\n",
            "epoch 28; iter: 0; batch classifier loss: 0.399843\n",
            "epoch 29; iter: 0; batch classifier loss: 0.395396\n",
            "epoch 30; iter: 0; batch classifier loss: 0.383149\n",
            "epoch 31; iter: 0; batch classifier loss: 0.357942\n",
            "epoch 32; iter: 0; batch classifier loss: 0.386045\n",
            "epoch 33; iter: 0; batch classifier loss: 0.351730\n",
            "epoch 34; iter: 0; batch classifier loss: 0.360051\n",
            "epoch 35; iter: 0; batch classifier loss: 0.398071\n",
            "epoch 36; iter: 0; batch classifier loss: 0.375769\n",
            "epoch 37; iter: 0; batch classifier loss: 0.407708\n",
            "epoch 38; iter: 0; batch classifier loss: 0.389316\n",
            "epoch 39; iter: 0; batch classifier loss: 0.380363\n",
            "epoch 40; iter: 0; batch classifier loss: 0.369908\n",
            "epoch 41; iter: 0; batch classifier loss: 0.401940\n",
            "epoch 42; iter: 0; batch classifier loss: 0.329296\n",
            "epoch 43; iter: 0; batch classifier loss: 0.359456\n",
            "epoch 44; iter: 0; batch classifier loss: 0.318574\n",
            "epoch 45; iter: 0; batch classifier loss: 0.340324\n",
            "epoch 46; iter: 0; batch classifier loss: 0.301991\n",
            "epoch 47; iter: 0; batch classifier loss: 0.367854\n",
            "epoch 48; iter: 0; batch classifier loss: 0.391613\n",
            "epoch 49; iter: 0; batch classifier loss: 0.348215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f3fb6ed0710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YFn1bc_0lkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
        "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAOtEg4e0lkh",
        "colab_type": "code",
        "outputId": "a0870700-2428-4310-ae3b-b3008977b7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean predicted outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean predicted outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_nodebiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - dataset metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Difference in mean predicted outcomes between unprivileged and privileged groups = -0.067344\n",
            "Test set: Difference in mean predicted outcomes between unprivileged and privileged groups = -0.147563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - classification metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Classification accuracy = 0.725000\n",
            "Test set: Balanced classification accuracy = 0.663337\n",
            "Test set: Disparate impact = 0.818770\n",
            "Test set: Equal opportunity difference = -0.055758\n",
            "Test set: Average odds difference = -0.109869\n",
            "Test set: Theil_index = 0.133592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsohGw3D0lkn",
        "colab_type": "text"
      },
      "source": [
        "### Apply in-processing algorithm based on adversarial learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlM9aG_w0lko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSnWzKHM0lkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learn parameters with debias set to True\n",
        "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='debiased_classifier',\n",
        "                          debias=True,\n",
        "                          #batch_size=50,\n",
        "                          #classifier_num_hidden_units=200,\n",
        "                          sess=sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wqPUOszv0lk1",
        "colab_type": "code",
        "outputId": "19a6f755-f41a-4910-f2ea-e447a98ad5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "source": [
        "debiased_model.fit(dataset_orig_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.867398; batch adversarial loss: 0.684761\n",
            "epoch 1; iter: 0; batch classifier loss: 0.695902; batch adversarial loss: 0.685513\n",
            "epoch 2; iter: 0; batch classifier loss: 0.596855; batch adversarial loss: 0.681464\n",
            "epoch 3; iter: 0; batch classifier loss: 0.564710; batch adversarial loss: 0.677372\n",
            "epoch 4; iter: 0; batch classifier loss: 0.528753; batch adversarial loss: 0.682609\n",
            "epoch 5; iter: 0; batch classifier loss: 0.526863; batch adversarial loss: 0.678734\n",
            "epoch 6; iter: 0; batch classifier loss: 0.517595; batch adversarial loss: 0.685336\n",
            "epoch 7; iter: 0; batch classifier loss: 0.536575; batch adversarial loss: 0.683176\n",
            "epoch 8; iter: 0; batch classifier loss: 0.592748; batch adversarial loss: 0.683826\n",
            "epoch 9; iter: 0; batch classifier loss: 0.481071; batch adversarial loss: 0.651167\n",
            "epoch 10; iter: 0; batch classifier loss: 0.498162; batch adversarial loss: 0.666030\n",
            "epoch 11; iter: 0; batch classifier loss: 0.524066; batch adversarial loss: 0.681267\n",
            "epoch 12; iter: 0; batch classifier loss: 0.518542; batch adversarial loss: 0.678495\n",
            "epoch 13; iter: 0; batch classifier loss: 0.472908; batch adversarial loss: 0.669097\n",
            "epoch 14; iter: 0; batch classifier loss: 0.464816; batch adversarial loss: 0.653094\n",
            "epoch 15; iter: 0; batch classifier loss: 0.421425; batch adversarial loss: 0.669732\n",
            "epoch 16; iter: 0; batch classifier loss: 0.515068; batch adversarial loss: 0.663689\n",
            "epoch 17; iter: 0; batch classifier loss: 0.403130; batch adversarial loss: 0.654832\n",
            "epoch 18; iter: 0; batch classifier loss: 0.441689; batch adversarial loss: 0.662580\n",
            "epoch 19; iter: 0; batch classifier loss: 0.420677; batch adversarial loss: 0.665018\n",
            "epoch 20; iter: 0; batch classifier loss: 0.499884; batch adversarial loss: 0.659404\n",
            "epoch 21; iter: 0; batch classifier loss: 0.403523; batch adversarial loss: 0.663722\n",
            "epoch 22; iter: 0; batch classifier loss: 0.410325; batch adversarial loss: 0.677043\n",
            "epoch 23; iter: 0; batch classifier loss: 0.427298; batch adversarial loss: 0.670175\n",
            "epoch 24; iter: 0; batch classifier loss: 0.459385; batch adversarial loss: 0.652221\n",
            "epoch 25; iter: 0; batch classifier loss: 0.439031; batch adversarial loss: 0.675704\n",
            "epoch 26; iter: 0; batch classifier loss: 0.463631; batch adversarial loss: 0.658534\n",
            "epoch 27; iter: 0; batch classifier loss: 0.454132; batch adversarial loss: 0.669676\n",
            "epoch 28; iter: 0; batch classifier loss: 0.447508; batch adversarial loss: 0.676750\n",
            "epoch 29; iter: 0; batch classifier loss: 0.366084; batch adversarial loss: 0.648031\n",
            "epoch 30; iter: 0; batch classifier loss: 0.403019; batch adversarial loss: 0.659624\n",
            "epoch 31; iter: 0; batch classifier loss: 0.389650; batch adversarial loss: 0.665757\n",
            "epoch 32; iter: 0; batch classifier loss: 0.436652; batch adversarial loss: 0.667974\n",
            "epoch 33; iter: 0; batch classifier loss: 0.388795; batch adversarial loss: 0.637918\n",
            "epoch 34; iter: 0; batch classifier loss: 0.352045; batch adversarial loss: 0.663836\n",
            "epoch 35; iter: 0; batch classifier loss: 0.448626; batch adversarial loss: 0.665076\n",
            "epoch 36; iter: 0; batch classifier loss: 0.380497; batch adversarial loss: 0.670140\n",
            "epoch 37; iter: 0; batch classifier loss: 0.398295; batch adversarial loss: 0.659218\n",
            "epoch 38; iter: 0; batch classifier loss: 0.428581; batch adversarial loss: 0.656557\n",
            "epoch 39; iter: 0; batch classifier loss: 0.400176; batch adversarial loss: 0.663850\n",
            "epoch 40; iter: 0; batch classifier loss: 0.356024; batch adversarial loss: 0.620308\n",
            "epoch 41; iter: 0; batch classifier loss: 0.304399; batch adversarial loss: 0.663223\n",
            "epoch 42; iter: 0; batch classifier loss: 0.428482; batch adversarial loss: 0.663327\n",
            "epoch 43; iter: 0; batch classifier loss: 0.367754; batch adversarial loss: 0.659352\n",
            "epoch 44; iter: 0; batch classifier loss: 0.429540; batch adversarial loss: 0.634350\n",
            "epoch 45; iter: 0; batch classifier loss: 0.375716; batch adversarial loss: 0.636750\n",
            "epoch 46; iter: 0; batch classifier loss: 0.372572; batch adversarial loss: 0.664264\n",
            "epoch 47; iter: 0; batch classifier loss: 0.345835; batch adversarial loss: 0.679242\n",
            "epoch 48; iter: 0; batch classifier loss: 0.421451; batch adversarial loss: 0.657184\n",
            "epoch 49; iter: 0; batch classifier loss: 0.318701; batch adversarial loss: 0.614243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f3f848d29e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSVlPz7b0lk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmFZ_tyW0lk_",
        "colab_type": "code",
        "outputId": "5bec7f82-e19d-49d0-f76d-80e2d689e098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "print(\"Train set: Difference in mean predicted outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "print(\"Test set: Difference in mean predicted outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "# Metrics for the dataset from model with debiasing\n",
        "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
        "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean predicted outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean predicted outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
        "\n",
        "\n",
        "\n",
        "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
        "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_debiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - dataset metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Difference in mean predicted outcomes between unprivileged and privileged groups = -0.067344\n",
            "Test set: Difference in mean predicted outcomes between unprivileged and privileged groups = -0.147563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Model - with debiasing - dataset metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Difference in mean predicted outcomes between unprivileged and privileged groups = -0.044168\n",
            "Test set: Difference in mean predicted outcomes between unprivileged and privileged groups = -0.120997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Plain model - without debiasing - classification metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Classification accuracy = 0.725000\n",
            "Test set: Balanced classification accuracy = 0.663337\n",
            "Test set: Disparate impact = 0.818770\n",
            "Test set: Equal opportunity difference = -0.055758\n",
            "Test set: Average odds difference = -0.109869\n",
            "Test set: Theil_index = 0.133592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "#### Model - with debiasing - classification metrics",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Classification accuracy = 0.735000\n",
            "Test set: Balanced classification accuracy = 0.677421\n",
            "Test set: Disparate impact = 0.847700\n",
            "Test set: Equal opportunity difference = -0.037640\n",
            "Test set: Average odds difference = -0.074144\n",
            "Test set: Theil_index = 0.132249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtIBZ2Majcg8",
        "colab_type": "text"
      },
      "source": [
        "##Part 4 - Difference between adversarial debiasing and reweighting.\n",
        "Reweighting detects bias in the training data and mitigates it before the data goes into the model. In part 2 we have seen how it mitigated effectively from -0.169905 to 0.0 the difference between the mean of the outcomes of the unprivilege group and the one of the privilege group. Adversarial debiasing is an in-processing technique that reduces an adversary's ability to determine the protected attribute from the predictions. In this approach the predictions do not carry information that the adversary can exploit, so it mitigates bias during the training. It is a very transparent method but also could improve accuracy. It can be seen in part 3, where the accuracy of the classification  went from 0.725000 to 0.735000. The disparate impact also improved, the closer to 1, the better. It went from 0.818770 to 0.847700. \n",
        "By experimenting with the definition of the privilege class, the difference of the mean of the outcomes became very low, so we did not need to apply mitigation on the bias in the training data that much. Instead we could inspect the model itself and we found that we can mitigate bias during the training process and we even could get an improvement in accuracy (from 0.725000 to 0.735000). \n",
        "My last thought on this is that given the issue of the size of the German data set, we could split the data so that we could use every sample for training like for example, cross-validation and find if there is need of more mitigation.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8wWlrNR0llF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "    References:\n",
        "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
        "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgPxmpoW0llG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}